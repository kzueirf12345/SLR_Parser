# SLRParser

Это задание по курсу "Введение в тензорные компиляторы" 4 семестр. Разбор грамматики простого арифтметического языка методом shift/reduce.

Авторы: 
-   Попов Владимир, Б01-411

## Зависимости

| Зависимость           | Минимальная версия    | Назначение                                    |
|-----------------------|-----------------------|-----------------------------------------------|
| **CMake**             | 3.26                  | Сборка проекта и зависимостей                 |
| **GCC / Clang**       | GCC 10 / Clang 11     | Компиляция C++20 кода                         |
| **Flex**              | 2.6.4                 | Лексический анализ                            |
| **Python**            | 3.6                   | Запуск тестов                                 |

### Установка зависимостей (Ubuntu/Debian)

#### 1. Системные зависимости
```bash
sudo apt update
sudo apt install -y \
    build-essential \
    git \
    wget \
    snap
```

#### 2. CMake

```bash
sudo snap install cmake --classic
# Если уже есть cmake из apt, а он скорее всего слишком старый, то для использования нового из snap выполните
echo 'export PATH="/snap/bin:$PATH"' >> ~/.bashrc # или ~/.zshrc
source ~/.bashrc # или ~/.zshrc
```


#### 3. Flex

```bash
sudo apt install flex libfl-dev
```

#### 4. Python

```bash
sudo apt install python3
```

## Сборка проекта

```bash
git clone https://github.com/kzueirf12345/SLR_Parser
cd SLR_Parser

cmake -B build -DCMAKE_BUILD_TYPE=Release # -DSANITIZE=ON включение санитайзеров
cmake --build build -j$(nproc)

# Запуск
./build/SLRParser [OPTIONS]
```

### Аргументы командой строки

```
Usage: ./build/SLRParser [OPTIONS]

Options:
  -h, --help           Show this help message
  -v, --verbose        Enable verbose output
  -i, --input <FILE>   Specify input file
  -o, --output <FILE>  Specify output file

```

## Грамматика
Основаная грамматика

```bnf
<start>     ::= <sum>

<sum>       ::= <sum> "+" <mul> | <sum> "-" <mul> | <mul>

<mul>       ::= <mul> "*" <brakets> | <mul> "/" <brakets> | <brakets>

<brakets>   ::= "(" <sum> ")" | NUM | ID
```

## Тесты

В директории ```tests/valid``` лежат корректные предложения, в директории ```tests/invalid``` - предложения, которые должны выдавать ошибку. Чтобы прогнать сразу все тесты, можно использовать питоновский скрипт ```tests/run_tests.py```, ответы положатся в папку ```tests/reports``` с расширение ```.popout``` и с теми же именами, как и входные данные.

## Структура проекта

В папке ```source``` лежат модули, каждый из которых подключается как статическая библиотека

Общий namespace - ```slr```

- **args** - парсер аргументов командой строки, а также ```IOManager```, который ответственен за входный и выходный потоки.
- **lexer** - Здесь лежит всё для лексического анализа. Используется ```Flex```, его файл находится в сорцах ```lexer.l```. Пользователь общается через класс ```Lexer```, который наследуется от ```yyFlexLexer```. 
- **args** - Здесь лежит всё для синтаксического анализа. 
    - ```Grammar``` описывает структуру грамматики и предоставляет интерфейс для взаимодействия с ней. Для нетерминала строится его множество Follow и First.
    - ```ParsingTable``` реализует SLR(1)-таблицу. С помощью методов ```closure``` и ```gotoState``` строится каноническое набор для грамматики и из неё заполняются таблицы Actions и Goto, с которыми дальше будет разбираться предложение.
    - ```Syntaxer``` реализует проверку массива токенов на соответствие грамматике. Используется алгоритм shift/reduce. Используется 2 стека - один для записи состояний, другой для записи текущих символов, чтобы позже отрисовывать результат. 
- **utils** - утилиты. В файле concole.hpp лежат красители для текста :). 

### Интуитивное описание алгоритма

Мы получаем на вход грамматику. В нашем случае будем считать, что она без эпсилон-правил, так будет легче парсить. 

Множество First строится итеративно. Для всех терминалов загружаем их самих. Для нетерминалов проходимся по всех продукциям и берём первый символ из правой части. Из-за отсутствия эпислон-правил, если это нетерминал, то оно все равно породит терминал, поэтому мы можем каждый ход цикла лезть всё глубже, чтобы дойти до терминала.

Построение Follow тоже итеративное, пока можем. Проходимся по каждому символу правой части каждого правила. Если справа от символа ничего нет, значит его follow равен follow нетерминала из которого он пораждался. Иначе смотрим следующий символ, и если он терминальный, то просто добавляем его, а если нет - то берём его follow.

Далее нам нужно получить состояния ДКА. Для этого пройдёмся по всем наборам правил с точкой (то есть с указанием позиции, что мы сейчас рассматриваем, далее буду называть итемами). Для набора итемов строим замыкание (closure), чтобы полностью описать состояние. Чтобы обойти все наборы, будем идти "в ширину". То есть рассматривать каждый символ и в наборе итемов "прошагивать" его, а полученный новый набор добовлять в очередь. Если шагать уже некуда, то этот итем в следующий набор мы уже не добавляем, он ничего нового не даст, им состояние определяться не будет. Начинаем, конечно, с замыкания исходного набора правил с точкой в самом начале.

Чтобы после выполнять разбор, нам нужно знать переходы между состояними. Для этого построим 2 таблицы

-   ```Action[state_num][terminal]``` = что мы делаем (либо shift, либо reduce, либо accept, иначе - ошибка)

Если надо сделать reduce, то нам нужно знать в какое состояние переходить, это храним в таблице 

- ```goto[state_num][non_terminal] = new_state_num```

goto-таблицу мы строим при помощи функции, которую уже обсуждали, gotoState. Получаем набор итемов, проверяем, есть ли он в массиве состояний и если да, то мы получили номер состояния.

Для построения action нам нужно понять, что делать из данного итема. Если точка находится НЕ в конце правой части, значит правило ещё необработанно до конца, значит свернуть его нельзя, поэтому делаем Shift. Иначе надо делать reduce, правило для которого ищем при помощи до этого построенной таблицы Follow. Стоит уточноить, что у нас расширенная грамматика, для того чтобы можно было определить конец. Если мы получили ```E' = E *```, значит разбор грамматики окончился, поэтому добавляем Accept.

Остаётся дело за малым. Получить массив токенов в Syntaxer, завести стек состояний, а дальше исходя из actions для либо shift, либо reduce, либо заканчивать.

